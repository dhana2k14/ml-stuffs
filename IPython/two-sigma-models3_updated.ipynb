{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, os\n",
    "from pandas.io.json import json_normalize\n",
    "# import missingno as msno\n",
    "import seaborn as sn\n",
    "from scipy import stats, sparse\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('D:/Kaggle/Two Sigma Connect')\n",
    "tr_df = pd.read_json('train.json')\n",
    "te_df = pd.read_json('test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count number of photos\n",
    "\n",
    "tr_df['num_photos'] = tr_df['photos'].apply(lambda x: len(x))\n",
    "te_df['num_photos'] = te_df['photos'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 200)\n",
    "pd.set_option('max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_to_use = ['price', 'num_photos', 'num_features', 'bedrooms', 'bathrooms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fs = ['manager_id', 'building_id', 'street_address', 'display_address']\n",
    "\n",
    "for f in fs:\n",
    "    if tr_df[f].dtype == 'object':\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(list(tr_df[f].values) + list(te_df[f].values))\n",
    "        tr_df[f] = le.transform(list(tr_df[f].values))\n",
    "        te_df[f] = le.transform(list(te_df[f].values))\n",
    "        feature_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index, row in tr_df.iterrows():\n",
    "    \n",
    "#     tr_df.loc[index, 'len_des'] = len(row['description'])\n",
    "\n",
    "    if 'Cats Allowed' in row['features']:\n",
    "        \n",
    "        tr_df.loc[index, 'pets_allowed'] = 1\n",
    "        \n",
    "        row['features'].remove('Cats Allowed')    \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        tr_df.loc[index, 'pets_allowed'] = 0       \n",
    "    \n",
    "    if 'Dogs Allowed' in row['features']:\n",
    "        \n",
    "        tr_df.loc[index, 'pets_allowed'] = 1\n",
    "            \n",
    "        row['features'].remove('Dogs Allowed')\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        tr_df.loc[index, 'pets_allowed'] = 0\n",
    "    \n",
    "            \n",
    "    if 'Hardwood Floors' in row['features']:       \n",
    "        \n",
    "        tr_df.loc[index, 'Hardwood_Floors'] = 1\n",
    "        row['features'].remove('Hardwood Floors')        \n",
    "    \n",
    "    else:        \n",
    "        \n",
    "        tr_df.loc[index, 'Hardwood_Floors'] = 0\n",
    "        \n",
    "    if 'Dishwasher' in row['features']:        \n",
    "        \n",
    "        tr_df.loc[index, 'dishwasher'] = 1\n",
    "        row['features'].remove('Dishwasher')\n",
    "        \n",
    "    else:        \n",
    "        \n",
    "        tr_df.loc[index, 'dishwasher'] = 0    \n",
    "    \n",
    "    if 'Doorman' in row['features']:        \n",
    "        \n",
    "        tr_df.loc[index, 'doorman_security'] = 1 \n",
    "        row['features'].remove('Doorman')\n",
    "        \n",
    "    else:        \n",
    "        \n",
    "        tr_df.loc[index, 'doorman_security'] = 0        \n",
    "    \n",
    "    if 'Elevator' in row['features']:        \n",
    "        \n",
    "        tr_df.loc[index, 'elevator'] = 1\n",
    "        row['features'].remove('Elevator')\n",
    "        \n",
    "    else:        \n",
    "        \n",
    "        tr_df.loc[index, 'elevator'] = 0         \n",
    "    \n",
    "    if 'No Fee' in row['features']:        \n",
    "        \n",
    "        tr_df.loc[index, 'no_fee'] = 1 \n",
    "        row['features'].remove('No Fee')\n",
    "        \n",
    "    else:        \n",
    "        \n",
    "        tr_df.loc[index, 'no_fee'] = 0   \n",
    "        \n",
    "        \n",
    "# Test set\n",
    "\n",
    "for index, row in te_df.iterrows():\n",
    "    \n",
    "    if 'Cats Allowed' in row['features']:\n",
    "        \n",
    "        te_df.loc[index, 'pets_allowed'] = 1\n",
    "        \n",
    "        row['features'].remove('Cats Allowed')    \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        te_df.loc[index, 'pets_allowed'] = 0       \n",
    "    \n",
    "    if 'Dogs Allowed' in row['features']:\n",
    "        \n",
    "        te_df.loc[index, 'pets_allowed'] = 1\n",
    "            \n",
    "        row['features'].remove('Dogs Allowed')\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        te_df.loc[index, 'pets_allowed'] = 0\n",
    "    \n",
    "            \n",
    "    if 'Hardwood Floors' in row['features']:       \n",
    "        \n",
    "        te_df.loc[index, 'Hardwood_Floors'] = 1\n",
    "        row['features'].remove('Hardwood Floors')        \n",
    "    \n",
    "    else:        \n",
    "        \n",
    "        te_df.loc[index, 'Hardwood_Floors'] = 0\n",
    "        \n",
    "    if 'Dishwasher' in row['features']:        \n",
    "        \n",
    "        te_df.loc[index, 'dishwasher'] = 1\n",
    "        row['features'].remove('Dishwasher')\n",
    "        \n",
    "    else:        \n",
    "        \n",
    "        te_df.loc[index, 'dishwasher'] = 0    \n",
    "    \n",
    "    if 'Doorman' in row['features']:        \n",
    "        \n",
    "        te_df.loc[index, 'doorman_security'] = 1 \n",
    "        row['features'].remove('Doorman')\n",
    "        \n",
    "    else:        \n",
    "        \n",
    "        te_df.loc[index, 'doorman_security'] = 0        \n",
    "    \n",
    "    if 'Elevator' in row['features']:        \n",
    "        \n",
    "        te_df.loc[index, 'elevator'] = 1\n",
    "        row['features'].remove('Elevator')\n",
    "        \n",
    "    else:        \n",
    "        \n",
    "        te_df.loc[index, 'elevator'] = 0         \n",
    "    \n",
    "    if 'No Fee' in row['features']:        \n",
    "        \n",
    "        te_df.loc[index, 'no_fee'] = 1 \n",
    "        row['features'].remove('No Fee')\n",
    "        \n",
    "    else:        \n",
    "        \n",
    "        te_df.loc[index, 'no_fee'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_to_use.extend(['pets_allowed', 'Hardwood_Floors','dishwasher','doorman_security','elevator','no_fee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print feature_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Baseline model\n",
    "\n",
    "# def model_fit(alg, train, test, predictors, printFeatureImportance = True):\n",
    "#     alg.fit(train[predictors], train['interest_level'])\n",
    "    \n",
    "#     # predict on the training set \n",
    "#     train_pred = alg.predict(train[predictors])\n",
    "#     test_predProb = alg.predict_proba(train[predictors])[:,1]\n",
    "    \n",
    "#     # Perform cross-validation\n",
    "    \n",
    "# #     if performCV:\n",
    "# #         cv_score = cross_validation.cross_val_score(alg,train[predictors], train['interest_level'], cv=cv_folds, scoring='roc_auc')\n",
    "        \n",
    "#     print \"\\n Model Report\"\n",
    "#     print \"Accuracy : %.4g\" %metrics.accuracy_score(train['interest_level'],train_pred)\n",
    "# #     print \"AUC Score (Train): %f\" %metrics.roc_auc_score(train['interest_level'],train_predProb)\n",
    "    \n",
    "# #     if performCV:\n",
    "# #         print \"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score))\n",
    "    \n",
    "#     if printFeatureImportance:\n",
    "#         feat_imp = pd.Series(alg.feature_importances_, predictors).sort_values(ascending=False)\n",
    "#         feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "#         plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_df['num_features'] = tr_df['features'].apply(lambda x: len(x))\n",
    "te_df['num_features'] = te_df['features'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_df['features'] = tr_df['features'].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
    "te_df['features'] = te_df['features'].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf = CountVectorizer(stop_words = 'english', max_features = 200)\n",
    "tr_sparse = tfidf.fit_transform(tr_df[['features','description']])\n",
    "te_sparse = tfidf.fit_transform(te_df[['features','description']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_X = sparse.hstack([tr_df[feature_to_use], tr_sparse]).tocsr()\n",
    "te_X = sparse.hstack([te_df[feature_to_use], te_sparse]).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_var_map = {'high':0, 'medium':1, 'low':2}\n",
    "tr_y = np.array(tr_df['interest_level'].apply(lambda x : target_var_map[x]))\n",
    "print (tr_X.shape, tr_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_X_arr = tr_X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print tr_df.groupby('interest_level')['interest_level'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_X_df = pd.SparseDataFrame([pd.SparseSeries(tr_X[i].toarray().ravel()) for i in np.arange(tr_X.shape[0])])\n",
    "tr_y_df = pd.DataFrame(tr_y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "te_X_df = pd.SparseDataFrame([ pd.SparseSeries(te_X[i].toarray().ravel()) for i in np.arange(te_X.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tuning parameters (Grid Search) - Step 1\n",
    "\n",
    "# predictors = [x for x in tr_df.columns if x not in ['created','description','features','latitude','longitude','photos']]\n",
    "param_test1 = {'n_estimators':range(20,80,10)}\n",
    "gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, \n",
    "                                                               min_samples_split=500,\n",
    "                                                               min_samples_leaf=50,\n",
    "                                                               max_depth=8,\n",
    "                                                               max_features='sqrt', \n",
    "                                                               subsample=0.8,\n",
    "                                                               random_state=10), \n",
    "                                                               param_grid = param_test1) \n",
    "#                                                                scoring='roc_auc',\n",
    "#                                                                n_jobs=4,\n",
    "#                                                                iid=False, \n",
    "#                                                                cv=5)\n",
    "gsearch1.fit(tr_X_arr,tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tune Tree Parameters - Step 1\n",
    "\n",
    "param_test2 = {'max_depth':range(5,16,2)}\n",
    "gsearch2 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, \n",
    "                                                               n_estimators = 70,\n",
    "                                                               min_samples_split=500,\n",
    "                                                               min_samples_leaf=50,\n",
    "                                                               max_features='sqrt', \n",
    "                                                               subsample=0.8,\n",
    "                                                               random_state=10), \n",
    "                                                               param_grid = param_test2)\n",
    "\n",
    "\n",
    "gsearch2.fit(tr_X_arr,tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tune Tree Parameters - Step 1\n",
    "\n",
    "param_test3 = {'min_samples_split':range(200,1001,200)}\n",
    "gsearch3 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, \n",
    "                                                               n_estimators = 70,\n",
    "                                                               max_depth = 15,\n",
    "                                                               min_samples_leaf = 30,\n",
    "                                                               max_features='sqrt', \n",
    "                                                               subsample=0.8,\n",
    "                                                               random_state=10), \n",
    "                                                               param_grid = param_test3)\n",
    "\n",
    "\n",
    "gsearch3.fit(tr_X_arr,tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.05, loss='deviance', max_depth=15,\n",
       "              max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=30,\n",
       "              min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=1000, presort='auto', random_state=10,\n",
       "              subsample=0.8, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune Tree Parameters - Step 1\n",
    "\n",
    "estimator = GradientBoostingClassifier(learning_rate = 0.05, n_estimators = 1500, max_depth = 15,\n",
    "                                                               min_samples_split = 200,\n",
    "                                                               min_samples_leaf = 30,\n",
    "                                                               max_features = 'sqrt',\n",
    "                                                               subsample=0.8,\n",
    "                                                               random_state=10)\n",
    "\n",
    "\n",
    "estimator.fit(tr_X_arr,tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8813\n"
     ]
    }
   ],
   "source": [
    "# predict the results on train set and compare with actual values\n",
    "\n",
    "# est = gsearch3.best_estimator_\n",
    "train_pred = estimator.predict(tr_X_arr)\n",
    "print 'Accuracy : %.4g' %metrics.accuracy_score(tr_y, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perform a grid search to fine tune with the parameters \n",
    "\n",
    "# param_grid = {'max_depth':[4, 6, 8]}\n",
    "\n",
    "# est = RandomForestClassifier(n_estimators = 2000)\n",
    "# gs_cv = GridSearchCV(est, param_grid).fit(tr_X_arr, tr_y)\n",
    "# print gs_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# est = RandomForestClassifier(n_estimators = 2000, max_depth = 8)\n",
    "# rfc = est.fit(tr_X_arr, tr_y)\n",
    "# print rfc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting Classifier \n",
    "\n",
    "# est = GradientBoostingClassifier(n_estimators = 2000, learning_rate = 0.1, max_depth = 8)\n",
    "# est.fit(tr_df_X, tr_df_y)\n",
    "# print est.train_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pred_X = est.predict(tr_df_X)\n",
    "# print confusion_matrix(pred_X, tr_df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# te_df_pred = te_df[feature_to_use]\n",
    "# print te_df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       high    medium       low\n",
      "0  0.058748  0.341402  0.599850\n",
      "1  0.013813  0.052648  0.933538\n",
      "2  0.006410  0.080507  0.913083\n",
      "3  0.105837  0.166390  0.727772\n",
      "4  0.018672  0.075598  0.905730\n"
     ]
    }
   ],
   "source": [
    "pred_te = estimator.predict_proba(te_X_df)\n",
    "pred_df = pd.DataFrame(pred_te, columns = ('high', 'medium', 'low'))\n",
    "print pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_df['listing_id'] = te_df.listing_id.values\n",
    "pred_df.to_csv('submission7_RF_2000_8.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create price bins (Random)\n",
    "\n",
    "# tr_df['price_bins'] = pd.cut(tr_df['price'], bins = 2, labels = ['Low Price', 'High Price'])\n",
    "# price_map = {'Low Price':0, 'High Price':1}\n",
    "\n",
    "# tr_df['price_bins'] = tr_df['price_bins'].apply(lambda x : price_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# how the number of photos & features have affected the interest level?\n",
    "\n",
    "# fig,(ax1, ax2) = plt.subplots(nrows = 2)\n",
    "# fig.set_size_inches(13,8)\n",
    "\n",
    "# tr_df_1 = tr_df[tr_df.num_photos <= 15]\n",
    "# tr_df_stack = tr_df_1.groupby(['num_photos', 'interest_level'])['num_photos'].count().unstack('interest_level').fillna(0)\n",
    "\n",
    "# tr_df_stack[['low', 'medium', 'high']].plot(kind = 'bar', ax = ax1)\n",
    "\n",
    "# tr_df_stack1 = tr_df.groupby(['num_features', 'interest_level'])['num_features'].count().unstack('interest_level').fillna(0)\n",
    "# tr_df_stack1[['low', 'medium', 'high']].plot(kind = 'bar', ax = ax2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# num_photos vs num_features vs interest levels\n",
    "\n",
    "# fig, (ax1) = plt.subplots()\n",
    "# fig.set_size_inches(13, 5)\n",
    "\n",
    "# ax1.scatter(tr_df[tr_df['interest_level'] == 'low']['num_photos'], tr_df[tr_df['interest_level'] == 'low']['num_features'], c = 'green', s = 40)\n",
    "# ax1.scatter(tr_df[tr_df['interest_level'] == 'medium']['num_photos'], tr_df[tr_df['interest_level'] == 'medium']['num_features'], c = 'red', s = 40)\n",
    "# ax1.scatter(tr_df[tr_df['interest_level'] == 'high']['num_photos'], tr_df[tr_df['interest_level'] == 'high']['num_features'], c = 'blue', s = 80)\n",
    "\n",
    "# ax1.set_xlabel('num_photos')\n",
    "# ax1.set_ylabel('num_features')\n",
    "\n",
    "# ax1.legend(('Low', 'Medium', 'High'), scatterpoints = 1, loc = 'upper right', fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For test set \n",
    "\n",
    "# te_df['price_bins'] = pd.cut(te_df['price'], bins = 2, labels = ['Low Price', 'High Price'])\n",
    "# price_map = {'Low Price':0, 'High Price':1}\n",
    "\n",
    "# te_df['price_bins'] = te_df['price_bins'].apply(lambda x : price_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# correlation between price and bed / bath rooms\n",
    "\n",
    "# corr = tr_df[['building_id', 'manager_id', 'price']].corr()\n",
    "# mask = np.array(corr)\n",
    "\n",
    "# mask[np.tril_indices_from(mask)] = False\n",
    "# fig,(ax) = plt.subplots()\n",
    "# fig.set_size_inches = (20, 10)\n",
    "# sn.heatmap(corr, mask = mask, annot = True, square = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,(axes) = plt.subplots(nrows = 3, ncols = 2)\n",
    "fig.set_size_inches(13, 15)\n",
    "\n",
    "pets = tr_df.groupby(['pets_allowed','interest_level'])['pets_allowed'].count().unstack().fillna(0)\n",
    "pets[['medium','high']].plot(kind = 'bar', ax = axes[0][0])\n",
    "\n",
    "floors = tr_df.groupby(['Hardwood_Floors','interest_level'])['Hardwood_Floors'].count().unstack().fillna(0)\n",
    "floors[['medium','high']].plot(kind = 'bar', ax = axes[0][1])\n",
    "\n",
    "dishwasher = tr_df.groupby(['dishwasher','interest_level'])['dishwasher'].count().unstack().fillna(0)\n",
    "dishwasher[['medium','high']].plot(kind = 'bar', ax = axes[1][0])\n",
    "\n",
    "doorman = tr_df.groupby(['doorman_security','interest_level'])['doorman_security'].count().unstack().fillna(0)\n",
    "doorman[['medium','high']].plot(kind = 'bar', ax = axes[1][1])\n",
    "\n",
    "elevator = tr_df.groupby(['elevator','interest_level'])['elevator'].count().unstack().fillna(0)\n",
    "elevator[['medium','high']].plot(kind = 'bar', ax = axes[2][0])\n",
    "\n",
    "nofee = tr_df.groupby(['no_fee','interest_level'])['no_fee'].count().unstack().fillna(0)\n",
    "nofee[['medium','high']].plot(kind = 'bar', ax = axes[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_fe = \"\"\n",
    "for index, row in tr_df_sample.iterrows():\n",
    "    for feature in row['features']:\n",
    "        text_fe = \" \".join([text_fe,\"_\".join(feature.strip().split(\" \"))]).strip()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "wordcloud = WordCloud(background_color='white', width=600, height=300, max_font_size=50, max_words=40).generate(text_fe)\n",
    "wordcloud.recolor(random_state=0)\n",
    "plt.imshow(wordcloud)\n",
    "plt.title(\"Wordcloud for features\", fontsize=30)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print tr_df_sample[['features', 'pets_allowed', 'Hardwood_Floors','dishwasher','doorman_security','elevator']].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_des = \"\"\n",
    "\n",
    "for index, row in tr_df.iterrows():\n",
    "    for feature in row['features']:\n",
    "        test_des = \" \".join([test_des, row['description']])\n",
    "    \n",
    "test_des = test_des.strip()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "wordcloud = WordCloud(background_color='white', width=600, height=300, max_font_size=50, max_words=40).generate(text_des)\n",
    "wordcloud.recolor(random_state=0)\n",
    "plt.imshow(wordcloud)\n",
    "plt.title(\"Wordcloud for description\", fontsize=30)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Predictive models \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
