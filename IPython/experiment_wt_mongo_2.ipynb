{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('D:/IoT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"TelemeteryData_July_August.csv\", nrows = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.assetName == 'Polo GT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Date', u'Time', u'active', u'assetName', u'date', u'accuracy',\n",
       "       u'address', u'age', u'altitude', u'heading', u'lat', u'lon', u'speed',\n",
       "       u'received', u'Business/Private', u'Engine Temp', u'Fuel Used',\n",
       "       u'Odometer', u'RPM', u'airflow', u'battery_voltage', u'can_01',\n",
       "       u'can_1F', u'can_5C', u'engine', u'event_id', u'fuel_level_02',\n",
       "       u'harsh_accel', u'harsh_brake', u'harsh_corner', u'hdop',\n",
       "       u'hours_00_counter', u'idle_counter', u'ignition', u'impact',\n",
       "       u'intake_temp', u'mil_status', u'moving', u'nudge', u'overspeed',\n",
       "       u'power_voltage', u'roaming', u'rsq', u'throttle'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "k_means = cluster.KMeans(n_clusters = 2)\n",
    "k_means.fit(df[['speed','power_voltage','battery_voltage']])\n",
    "\n",
    "print k_means.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date   Time active assetName            date  accuracy  \\\n",
      "1  6/30/2016   0:04  False   Polo GT  6/30/2016 0:04        11   \n",
      "3  6/30/2016   0:19  False   Polo GT  6/30/2016 0:19        11   \n",
      "5  6/30/2016   0:34  False   Polo GT  6/30/2016 0:34        11   \n",
      "7  6/30/2016   0:49  False   Polo GT  6/30/2016 0:49        11   \n",
      "9  6/30/2016   1:04  False   Polo GT  6/30/2016 1:04         9   \n",
      "\n",
      "                                          address  age  altitude  heading  \\\n",
      "1  Amman Koil Street, Selaiyur, Tamil Nadu, India    0        13        0   \n",
      "3  Amman Koil Street, Selaiyur, Tamil Nadu, India    0        13        0   \n",
      "5  Amman Koil Street, Selaiyur, Tamil Nadu, India    0        13        0   \n",
      "7  Amman Koil Street, Selaiyur, Tamil Nadu, India    0        13        0   \n",
      "9  Amman Koil Street, Selaiyur, Tamil Nadu, India    0         7        0   \n",
      "\n",
      "     ...     intake_temp  mil_status  moving nudge overspeed  power_voltage  \\\n",
      "1    ...             NaN         NaN       0   NaN       NaN          11.83   \n",
      "3    ...             NaN         NaN       0   NaN       NaN          11.81   \n",
      "5    ...             NaN         NaN       0   NaN       NaN          11.86   \n",
      "7    ...             NaN         NaN       0   NaN       NaN          11.83   \n",
      "9    ...             NaN         NaN       0   NaN       NaN          11.86   \n",
      "\n",
      "   roaming  rsq  throttle  clus_mem  \n",
      "1        1   15       NaN         1  \n",
      "3        1   16       NaN         1  \n",
      "5        1   17       NaN         1  \n",
      "7        1   18       NaN         1  \n",
      "9        1   19       NaN         1  \n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "df['clus_mem'] = k_means.labels_\n",
    "print df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017 1 5\n"
     ]
    }
   ],
   "source": [
    "dt = '2017/1/5'\n",
    "yr  = pd.to_datetime(dt).year\n",
    "mo  = pd.to_datetime(dt).month\n",
    "date = pd.to_datetime(dt).day\n",
    "\n",
    "print yr, mo, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import datetime\n",
    "from pandas.io.json import json_normalize\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"mongodb://172.25.69.155:27017\")\n",
    "db = client['KeyTelematics']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print pd.to_datetime(start_date).year\n",
    "# print pd.to_datetime(start_date).month\n",
    "# print pd.to_datetime(start_date).day\n",
    "\n",
    "# print pd.to_datetime(end_date).year\n",
    "# print pd.to_datetime(end_date).month\n",
    "# print pd.to_datetime(end_date).day\n",
    "\n",
    "# cursor = db.TelemeteryData_June2016_Test.find(                                             \n",
    "#             {             \n",
    "#             \"telemetryData.assetName\":{'$eq':assetName},\n",
    "#             # \"customData.date\":{\"$in\":[start_date, end_date]}\n",
    "#             \"telemetryData.date\":\n",
    "#                                 {\"$gte\":datetime.datetime(  pd.to_datetime(start_date).year,\n",
    "#                                                             pd.to_datetime(start_date).month, \n",
    "#                                                             pd.to_datetime(start_date).day)\n",
    "# #                                  \"$lt\":datetime.datetime(  pd.to_datetime(end_date).year,\n",
    "# #                                                             pd.to_datetime(end_date).month, \n",
    "# #                                                             pd.to_datetime(end_date).day)\n",
    "#                                 }\n",
    "#             },                                                     \n",
    "#             {'telemetryData':1}) \n",
    "\n",
    "# df_json = list(cursor)\n",
    "# df_cursor = json_normalize(df_json)\n",
    "\n",
    "\n",
    "# print df_cursor['telemetryData.date'].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_extractor(assetName, start_date, end_date):\n",
    "    \n",
    "        cursor = db.TelemeteryData_June2016_Test.find(                                             \n",
    "            {             \n",
    "            \"telemetryData.assetName\":{'$eq':assetName},\n",
    "            \"telemetryData.date\":\n",
    "                                {\"$gte\":datetime.datetime(pd.to_datetime(start_date).year,\n",
    "                                                            pd.to_datetime(start_date).month, \n",
    "                                                            pd.to_datetime(start_date).day),\n",
    "                                 \"$lte\":datetime.datetime(pd.to_datetime(end_date).year,\n",
    "                                                            pd.to_datetime(end_date).month, \n",
    "                                                            pd.to_datetime(end_date).day)\n",
    "                                }},                                                     \n",
    "            {'telemetryData':1, 'customData':1})          \n",
    "            \n",
    "        df_json = list(cursor)\n",
    "        df_cursor = json_normalize(df_json)\n",
    "        df_cursor.columns = df_cursor.columns.str.replace('location.','')\n",
    "        df_cursor.columns = df_cursor.columns.str.replace('telemetryData.','')\n",
    "        df_cursor.columns = df_cursor.columns.str.replace('telemetry.','')\n",
    "        df_cursor['date_utc'] = pd.to_datetime(df_cursor.date).dt.tz_localize('UTC').dt.tz_convert('Asia/Kolkata').dt.tz_localize(None)\n",
    "        df_cursor.sort_values(['date_utc'], ascending = True)\n",
    "        df_cursor['date_use'] = df_cursor.date_utc.apply(lambda x : x.strftime('%Y-%m-%d'))\n",
    "        df_cursor['dup_loc'] = df_cursor.groupby(['date_use','lat', 'lon']).cumcount().apply(lambda x: x + 1)\n",
    "        df_asset = df_cursor.loc[(df_cursor.assetName == assetName) & (df_cursor.dup_loc == 1) & (df_cursor.engine > 0) & (df_cursor.ignition > 0), :].copy()\n",
    "        df_asset = df_asset.reset_index(drop = True)\n",
    "        \n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        grouped = df_asset.groupby('date_use')\n",
    "\n",
    "        for name, group in grouped:\n",
    "\n",
    "                g = pd.DataFrame(group)\n",
    "                g['time_diff'] = (g.date_utc - g.date_utc.shift(1)).apply(lambda x: x/np.timedelta64(1, 'm'))                                       \n",
    "                g['row_num']  = g.groupby('date_use').cumcount().apply(lambda x : x + 1)\n",
    "                \n",
    "                for index, row in g.iterrows():\n",
    "\n",
    "                        if g.loc[index, 'row_num'] == 1:\n",
    "\n",
    "                                g.loc[index, 'Trip'] = 1\n",
    "\n",
    "                        else:\n",
    "\n",
    "                                if g.loc[index, 'time_diff'] > 15.0:\n",
    "\n",
    "                                        g.loc[index, 'Trip'] = g.loc[pd.to_numeric(index) - 1, 'Trip'] + 1                                                                        \n",
    "                              \n",
    "                                else:\n",
    "                                        g.loc[index,'Trip'] = g.loc[pd.to_numeric(index) - 1, 'Trip']\n",
    "                    \n",
    "               \n",
    "                df2 = pd.DataFrame()\n",
    "                \n",
    "                grp = g.groupby('Trip')\n",
    "\n",
    "                for name, group in grp:\n",
    "                    \n",
    "                    g1 = pd.DataFrame(group)            \n",
    "                    g1['avg_speed'] = round(g1['speed'].mean(),0)\n",
    "                    g1['max_speed'] = round(g1['speed'].max(),0)\n",
    "                    g1['total_distance'] = round(g1.Odometer.iloc[-1] - g1.Odometer.iloc[0], 0)                            \n",
    "                    g1['diff_speed'] = g1.speed - g1.speed.shift(1).fillna(np.NaN)\n",
    "                    g1.diff_speed.fillna(0, inplace = True)\n",
    "\n",
    "                    for index, row in g1.iterrows():\n",
    "                                    \n",
    "                        if g1.loc[index, 'diff_speed'] <= -40:\n",
    "                            \n",
    "                            g1.loc[index, 'harsh_brake'] = 1\n",
    "                        \n",
    "                        else:\n",
    "                            \n",
    "                            g1.loc[index, 'harsh_brake'] = 0\n",
    "\n",
    "                        if g1.loc[index, 'diff_speed'] >= 40:\n",
    "\n",
    "                            g1.loc[index, 'harsh_accl'] = 1\n",
    "\n",
    "                        else:\n",
    "                            \n",
    "                            g1.loc[index, 'harsh_accl'] = 0\n",
    "\n",
    "                    \n",
    "                    g1['harsh_brake'] = g1['harsh_brake'].sum()\n",
    "                    g1['harsh_accl'] = g1['harsh_accl'].sum()\n",
    "                    df2 = df2.append(g1)   \n",
    "                                 \n",
    "                df = df.append(df2)\n",
    "                \n",
    "        df['row'] = df.groupby(['date_use','Trip']).cumcount().apply(lambda x :x + 1)\n",
    "        df = df.loc[df.row == 1, ['assetName','date_use','Trip']].copy()\n",
    "        print df.head(20)\n",
    "                                          \n",
    "#                 return pd.DataFrame({assetName : df.assetName,\n",
    "#                                      assetName +'_Date': df.date_use,\n",
    "#                                      assetName+'_speed': df.speed,\n",
    "#                                      assetName+'_avg_speed': df.avg_speed,\n",
    "#                                      assetName+'_trip_distance':df.totalDist_trip,\n",
    "#                                      assetName+'_harsh_accl': df.harsh_accl,\n",
    "#                                      assetName+'_harsh_brake': df.harsh_brake,\n",
    "#                                      assetName+'_trip': df.Trip})\n",
    "                \n",
    "    \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Kmeans clustering\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(vehicle_name, start_dt, end_date):\n",
    "        df = data_extractor(vehicle_name, start_dt, end_date)\n",
    "        df['ticker1'] = df[vehicle_name]\n",
    "        k_means = KMeans(n_clusters = 2, init = 'k-means++')\n",
    "        k_means.fit(df[[vehicle_name+'_avg_speed',vehicle_name+'_harsh_accl',vehicle_name+'_harsh_brake',vehicle_name+'_trip' ]])\n",
    "        return k_means.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     assetName    date_use  Trip\n",
      "0      Polo GT  2017-01-05   1.0\n",
      "198    Polo GT  2017-01-05   2.0\n",
      "419    Polo GT  2017-01-06   1.0\n",
      "631    Polo GT  2017-01-06   2.0\n",
      "723    Polo GT  2017-01-06   3.0\n",
      "843    Polo GT  2017-01-06   4.0\n",
      "1060   Polo GT  2017-01-07   1.0\n",
      "1153   Polo GT  2017-01-07   2.0\n",
      "1220   Polo GT  2017-01-07   3.0\n",
      "1620   Polo GT  2017-01-07   4.0\n",
      "1776   Polo GT  2017-01-07   5.0\n",
      "2010   Polo GT  2017-01-07   6.0\n",
      "2029   Polo GT  2017-01-08   1.0\n",
      "2135   Polo GT  2017-01-08   2.0\n",
      "2301   Polo GT  2017-01-08   3.0\n",
      "2412   Polo GT  2017-01-08   4.0\n",
      "2683   Polo GT  2017-01-08   5.0\n",
      "3010   Polo GT  2017-01-09   1.0\n"
     ]
    }
   ],
   "source": [
    "data_extractor('Polo GT', '1/1/2017', '10/1/2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name IsolationForest",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b85c1488ee56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIsolationForest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name IsolationForest"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name IsolationForest",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-16c749a8861a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIsolationForest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name IsolationForest"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# Generate train data\n",
    "X = 0.3 * rng.randn(100, 2)\n",
    "X_train = np.r_[X + 2, X - 2]\n",
    "# Generate some regular novel observations\n",
    "X = 0.3 * rng.randn(20, 2)\n",
    "X_test = np.r_[X + 2, X - 2]\n",
    "# Generate some abnormal novel observations\n",
    "X_outliers = rng.uniform(low=-4, high=4, size=(20, 2))\n",
    "\n",
    "# fit the model\n",
    "clf = IsolationForest(max_samples=100, random_state=rng)\n",
    "clf.fit(X_train)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_pred_outliers = clf.predict(X_outliers)\n",
    "\n",
    "# plot the line, the samples, and the nearest vectors to the plane\n",
    "xx, yy = np.meshgrid(np.linspace(-5, 5, 50), np.linspace(-5, 5, 50))\n",
    "Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.title(\"IsolationForest\")\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.Blues_r)\n",
    "\n",
    "b1 = plt.scatter(X_train[:, 0], X_train[:, 1], c='white')\n",
    "b2 = plt.scatter(X_test[:, 0], X_test[:, 1], c='green')\n",
    "c = plt.scatter(X_outliers[:, 0], X_outliers[:, 1], c='red')\n",
    "plt.axis('tight')\n",
    "plt.xlim((-5, 5))\n",
    "plt.ylim((-5, 5))\n",
    "plt.legend([b1, b2, c],\n",
    "           [\"training observations\",\n",
    "            \"new regular observations\", \"new abnormal observations\"],\n",
    "           loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
